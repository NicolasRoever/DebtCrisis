import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from datetime import timedelta
import seaborn as sns


def clean_llm_output_data(
    llm_output_data: pd.DataFrame,
    raw_transcript_data: pd.DataFrame,
    training_data: pd.DataFrame,
):  # -> pd.DataFrame:
    """Clean the output data from the LLM model to be used for analysis.

    Args:
    llm_output_data: The output data from the LLM model.
    raw_transcript_data: The raw transcript data.
    training_data: The training data used to train the LLM model.

    Returns:
    The cleaned LLM output data.

    """

    # Add Transcript_ID
    full_data = llm_output_data.merge(
        training_data,
        how="left",
        left_on="Snippet_ID",
        right_on="Snippet_ID",
        validate="one_to_one",
    )

    # Check if 'Snippet' and 'Excerpt' columns are equal
    are_columns_equal = full_data["Snippet"] == full_data["Excerpt"]
    all_equal = are_columns_equal.all()
    if not all_equal:
        raise ValueError("The 'Snippet' and 'Excerpt' columns are not equal.")

    # Merge with clean_transcripts on 'Transcript_ID'
    full_data = full_data.merge(
        raw_transcript_data,
        how="left",
        left_on="Transcript_ID",
        right_on="Transcript_ID",
        validate="many_to_one",
    )

    # Count the number of rows before dropping NaN values
    before_drop = len(full_data)

    # Drop rows with NaN values in the "Prediction" column
    full_data.dropna(subset=["Prediction"], inplace=True)

    # Count the number of rows after dropping NaN values
    after_drop = len(full_data)

    # Calculate and print the number of observations dropped
    observations_dropped = before_drop - after_drop
    print(f"Number of observations dropped: {observations_dropped}")

    return full_data


def calculate_gpt_sentiment_index(
    preprocessed_data, country_under_study, day_window=90
):
    """This function calculates the sentiment index taking as input the preprocessed
    data generated by earlier functions in this script.

    Args:
        preprocessed_data (pd.DataFrame): Dataframe with the data from gpt
        countries_under_study (list): List of countries to consider
        day_window (int): Number of days to consider for the sentiment index

    Returns:
        pd.DataFrame: Dataframe with the sentiment index
        columns: Date (pd.DateTime): Date of sentiment index
                Sentiment_Index_country (int): Sentiment index for the country (there is one of such columns for every country under study.)

    """

    # Ensure 'Date' column in preprocessed_data is of datetime type
    preprocessed_data["Date"] = pd.to_datetime(preprocessed_data["Date"])

    # Create date range from January 2003 to January 2023
    date_range = pd.date_range(start="1/1/2003", end="1/1/2023")

    # Initialize a DataFrame with 'Date' column
    result_df = pd.DataFrame(date_range, columns=["Date"])
    result_df["Country"] = country_under_study

    # Set 'Date' as index for efficient lookup
    result_df.set_index("Date", inplace=True)
    preprocessed_data.set_index("Date", inplace=True)

    # Iterate over each date
    for date in date_range:
        # Iterate over each country
        # Calculate the sum of the Sentiment_Index_McDonald_{country} column over the prior day_window days
        end_date = date
        start_date = end_date - pd.Timedelta(
            days=day_window
        )  # start date is day_window days before the end date
        # if date == pd.Timestamp("2023-01-02"):
        #    breakpoint()
        # Extract the data for the window
        # Filter for observations within the date range using boolean indexing
        mask = (preprocessed_data.index >= start_date) & (
            preprocessed_data.index <= end_date
        )
        window_data = preprocessed_data.loc[mask, "Prediction"]

        # Calculate the sentiment index
        sentiment_index = (
            window_data.sum() / len(window_data) if len(window_data) > 0 else np.nan
        )

        # Add the sentiment index to the result DataFrame
        result_df.loc[date, f"Sentiment_GPT"] = sentiment_index

    return result_df.reset_index()


def plot_sentiment_indices_and_bond_yields(
    gpt_sentiment_index: pd.DataFrame,
    mcdonald_sentiment_index: pd.DataFrame,
    bond_yield_data: pd.DataFrame,
    country_under_study: str,
    color_scheme=["#3c5488", "#e64b35", "#4dbbd5", "#00a087", "#f39b7f"],
):
    # Prepare Data
    bond_yield_data = bond_yield_data[
        bond_yield_data["Date"] >= gpt_sentiment_index["Date"].min()
    ]
    quarter_dates = bond_yield_data["Date"]
    gpt_quarter_data = gpt_sentiment_index[
        gpt_sentiment_index["Date"].isin(quarter_dates)
    ]
    mcdonald_quarter_data = mcdonald_sentiment_index[
        mcdonald_sentiment_index["Date"].isin(quarter_dates)
    ]

    sns.set_style("white")

    # Step 3: Plotting
    fig, ax1 = plt.subplots(figsize=(10, 6))

    # Plot sentiment from full_data
    ax1.plot(
        gpt_quarter_data["Date"],
        gpt_quarter_data[f"Sentiment_GPT"],
        label="Sentiment GPT",
        color=color_scheme[0],
        alpha=0.9,
    )
    ax1.set_xlabel("Date")
    ax1.set_ylabel("Sentiment from GPT", color=color_scheme[0])
    ax1.tick_params(axis="y", labelcolor=color_scheme[0])
    ax1.invert_yaxis()

    # Create a second y-axis for bond yield
    ax2 = ax1.twinx()
    ax2.plot(
        bond_yield_data["Date"],
        bond_yield_data["10y_Maturity_Bond_Yield"],
        label="Bond Yield",
        color=color_scheme[1],
    )
    ax2.set_ylabel("Bond Yield", color=color_scheme[1])
    ax2.tick_params(axis="y", labelcolor=color_scheme[1])

    # Create a third y-axis for sentiment in df
    ax3 = ax1.twinx()
    # Offset the right spine of ax3. The ticks and label have already been
    # colored in ax2, so only the spine needs to be colored.
    ax3.spines["right"].set_position(("outward", 60))  # Offset the third axis
    ax3.plot(
        mcdonald_quarter_data["Date"],
        mcdonald_quarter_data[f"Sentiment_Index_McDonald_{country_under_study}"],
        label="Sentiment McDonald",
        color=color_scheme[2],
        alpha=0.9,
    )
    ax3.set_ylabel("Sentiment from Loughran and McDonald", color=color_scheme[2])
    ax3.tick_params(axis="y", labelcolor=color_scheme[2])
    ax3.invert_yaxis()  # Invert the y-axis for sentiment from Loughran and McDonald

    plt.tight_layout()

    plt.title(f"Sentiment and Bond Yield Over Time for {country_under_study}")

    return fig


def create_correlation_matrix_between_sentiment_indices_and_yields(
    gpt_sentiment_index: pd.DataFrame,
    mcdonald_sentiment_index: pd.DataFrame,
    bond_yield_data: pd.DataFrame,
    country_under_study: str,
    color_scheme=["#3c5488", "#e64b35", "#4dbbd5", "#00a087", "#f39b7f"],
):
    # Prepare Data
    quarter_dates = bond_yield_data["Date"]
    gpt_quarter_data = gpt_sentiment_index[
        gpt_sentiment_index["Date"].isin(quarter_dates)
    ]
    mcdonald_quarter_data = mcdonald_sentiment_index[
        mcdonald_sentiment_index["Date"].isin(quarter_dates)
    ]

    sns.set_style("white")

    # Step 2: Merge DataFrames
    # Ensure that the Date columns are of the same data type to avoid merge issues
    merged_data = pd.merge(bond_yield_data, gpt_quarter_data, on="Date", how="inner")
    merged_data = pd.merge(merged_data, mcdonald_quarter_data, on="Date", how="inner")

    # Rename columns for clarity if needed
    merged_data.rename(
        columns={
            "10y_Maturity_Bond_Yield": "Bond_Yield",
            f"Sentiment_GPT": "GPT_Index",
            f"Sentiment_Index_McDonald_{country_under_study}": "McDonald_Index",
        },
        inplace=True,
    )

    # Step 3: Calculate Correlation Matrix
    correlation_matrix = merged_data[
        ["Bond_Yield", "GPT_Index", "McDonald_Index"]
    ].corr()

    # Plotting the correlation matrix
    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, fmt=".2f", linewidths=0.5)
    plt.title(
        f"Correlation Matrix {country_under_study} between Bond Yield, GPT Index, and McDonald Index"
    )

    plt.tight_layout()

    return plt
