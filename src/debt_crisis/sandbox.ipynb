{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve Preprocessing of Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/df_transcripts_clean_step_2_negative_20_.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/gpt_sentiment_data/df_random_transcript_snippets.xlsx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Snippet\"] = data[\"Snippet\"].apply(\n",
    "    lambda x: \"\".join(\n",
    "        x.replace(\"[\", \"\")\n",
    "        .replace(\"]\", \"\")\n",
    "        .replace(\"'\", \"\")\n",
    "        .replace(\",\", \"\")\n",
    "        .replace(\"-\", \"\"),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Snippet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join(data.loc[:, \"Snippet\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=\"Snippet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/gpt_sentiment_data/df_random_transcript_snippets_NR.xlsx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Training Data for GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/df_transcripts_raw.pkl\",\n",
    ")\n",
    "full_data[\"Date\"] = pd.to_datetime(full_data[\"Date\"])\n",
    "full_data[\"Transcript\"] = full_data[\"Transcript\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_names = pd.read_excel(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/src/debt_crisis/data/country_names/country_names.xlsx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_with_all_country_words(country_names_file):\n",
    "    # Flatten the DataFrame to a single list\n",
    "    country_words = country_names_file.values.flatten()\n",
    "\n",
    "    # Remove NaN values\n",
    "    country_words = [word for word in country_words if pd.notna(word)]\n",
    "\n",
    "    # Create a set of unique words\n",
    "    return set(country_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_words_set = create_set_with_all_country_words(country_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = full_data.sample(1)\n",
    "transcript_id = row[\"Transcript_ID\"].values[0]\n",
    "occuring_words = country_words_set.intersection(\n",
    "    set(row[\"Transcript\"].str.split().values[0]),\n",
    ")\n",
    "occuring_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_text_snippet_if_there_is_country_mentioned(\n",
    "    full_data,\n",
    "    country_words_set,\n",
    "    context=50,\n",
    "):\n",
    "    row = full_data.sample(1)\n",
    "    transcript_id = row[\"Transcript_ID\"].values[0]\n",
    "    occuring_words = country_words_set.intersection(\n",
    "        set(row[\"Transcript\"].str.split().values[0]),\n",
    "    )\n",
    "\n",
    "    if occuring_words:\n",
    "        # Randomly pick a word\n",
    "        word = random.choice(list(occuring_words))\n",
    "\n",
    "        # Get the 'Transcript'\n",
    "        transcript = row[\"Transcript\"].values[0]\n",
    "\n",
    "        # Split the 'Transcript' into words\n",
    "        words = transcript.split()\n",
    "\n",
    "        # Find the index of the word\n",
    "        index = words.index(word)\n",
    "\n",
    "        # Get the 40 preceding and succeeding words\n",
    "        start = max(0, index - context)\n",
    "        end = min(len(words), index + context)\n",
    "        snippet = words[start:end]\n",
    "\n",
    "        # Create a single-row DataFrame\n",
    "        result = pd.DataFrame(\n",
    "            {\"Keyword\": [word], \"Transcript_ID\": [transcript_id], \"Snippet\": [snippet]},\n",
    "        )\n",
    "\n",
    "        print(\"Occurence\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = pd.DataFrame()\n",
    "\n",
    "for i in range(100):\n",
    "    country_words_set = create_set_with_all_country_words(country_names)\n",
    "    single_snippet = get_a_text_snippet_if_there_is_country_mentioned(\n",
    "        full_data,\n",
    "        country_words_set,\n",
    "    )\n",
    "\n",
    "    if single_snippet is not None:\n",
    "        final_output = pd.concat([final_output, single_snippet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which\n",
    "row = full_data.sample(1)\n",
    "set(row[\"Transcript\"].str.split().values[0])\n",
    "occurence = country_words_set.intersection(set(row[\"Transcript\"].str.split().values[0]))\n",
    "occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick a word\n",
    "word = random.choice(list(occurence))\n",
    "\n",
    "# Get the 'Transcript'\n",
    "transcript = row[\"Transcript\"].values[0]\n",
    "\n",
    "# Split the 'Transcript' into words\n",
    "words = transcript.split()\n",
    "\n",
    "# Find the index of the word\n",
    "index = words.index(word)\n",
    "\n",
    "\n",
    "# Get the 40 preceding and succeeding words\n",
    "start = max(0, index - 50)\n",
    "end = min(len(words), index + 50)\n",
    "snippet = words[start:end]\n",
    "\n",
    "print(\" \".join(snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame\n",
    "filtered_data = full_data[\n",
    "    full_data.apply(\n",
    "        lambda x: any(word in x[\"Transcript\"] for word in country_words_list)\n",
    "        and print(f\"Processing row: {x.name}\")\n",
    "        or True,\n",
    "        axis=1,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan: \n",
    "\n",
    "1. Check which word occurs\n",
    "2. Then get context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_country_names(country, country_names_file):\n",
    "    \"\"\"THis function extracts the country names from the country names file.\"\"\"\n",
    "    country_row = country_names_file[\n",
    "        country_names_file[\"name\"].str.lower() == country.lower()\n",
    "    ]\n",
    "    if not country_row.empty:\n",
    "        country_names = set(country_row.iloc[0].values.tolist())\n",
    "    else:\n",
    "        country_names = set()\n",
    "\n",
    "    return country_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_appearance_index_from_transcript_text(transcript_words, country_names):\n",
    "    \"\"\"Get a list of indices where any of the country names or their alternate names are\n",
    "    found in the transcript.\n",
    "\n",
    "    Args:\n",
    "        transcript (str): Earnings call transcript\n",
    "        country_names (set): Set of country names and alternate names\n",
    "\n",
    "    Returns:\n",
    "        list: List of indices where country names or alternate names are found\n",
    "\n",
    "    \"\"\"\n",
    "    # Initialize a list to store indices\n",
    "    country_indices = []\n",
    "\n",
    "    # Iterate through words and check for country names or alternate names\n",
    "    for i, word in enumerate(transcript_words):\n",
    "        if word in country_names:\n",
    "            country_indices.append(i)\n",
    "\n",
    "    return country_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_country_transcript_snippet(\n",
    "    data,\n",
    "    countries_under_study,\n",
    "    country_names_file,\n",
    "    window_size=40,\n",
    "):\n",
    "    # Randomly select a row from the data\n",
    "    row = data.sample(1)\n",
    "\n",
    "    transcript_id = row[\"Transcript_ID\"].values[0]\n",
    "\n",
    "    # Get the transcript text\n",
    "    transcript = row[\"Transcript\"].values[0]\n",
    "\n",
    "    # Split the transcript into words\n",
    "    transcript_words = transcript.split()\n",
    "\n",
    "    for country in countries_under_study:\n",
    "        country_names = obtain_country_names(country, country_names_file)\n",
    "\n",
    "        # Find the indices of the country in the transcript\n",
    "        country_indices = get_country_appearance_index_from_transcript_text(\n",
    "            transcript_words,\n",
    "            country_names,\n",
    "        )\n",
    "\n",
    "        # If the country is not in the transcript, return an empty string\n",
    "        if not country_indices:\n",
    "            return None\n",
    "\n",
    "        # Randomly select an index from country_indices\n",
    "        index = random.choice(country_indices)\n",
    "\n",
    "        # Get the start and end indices for the snippet\n",
    "        start = max(0, index - window_size)\n",
    "        end = min(len(transcript_words), index + window_size)\n",
    "\n",
    "        # Get the snippet\n",
    "        snippet = \" \".join(transcript_words[start:end])\n",
    "\n",
    "        # Create a single-row DataFrame\n",
    "        result = pd.DataFrame(\n",
    "            {\n",
    "                \"Country\": [country],\n",
    "                \"Transcript_ID\": [transcript_id],\n",
    "                \"Snippet\": [snippet],\n",
    "            },\n",
    "        )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Loop until df has 200 rows\n",
    "while len(df) < 10:\n",
    "    # Execute the function\n",
    "    result = get_random_country_transcript_snippet(\n",
    "        full_data,\n",
    "        COUNTRIES_UNDER_STUDY,\n",
    "        country_names_file=country_names,\n",
    "        window_size=40,\n",
    "    )\n",
    "\n",
    "    # If the result is not empty, append it to df\n",
    "    if result is not None:\n",
    "        df = pd.concat([df, result])\n",
    "        print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Function to Return Regression Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_data = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/event_study_approach/event_study_full_model_data_negative_and_positive_20_.pkl\",\n",
    ")\n",
    "from debt_crisis.config import EVENT_STUDY_COUNTRIES, EVENT_STUDY_TIME_PERIOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_column_names_from_regression_formula(formula):\n",
    "    \"\"\"This function takes in a string giving a regression formula and returns a list with the variable names.\"\"\"\n",
    "    # Split the formula into left and right parts\n",
    "    left, right = formula.split(\"~\")\n",
    "\n",
    "    # Extract the terms from the right part of the formula\n",
    "    terms = re.split(r\"\\+\", right.strip())\n",
    "\n",
    "    # Remove the 'Q('')' and 'C('')' wrappers and strip whitespace\n",
    "    column_names = [\n",
    "        re.sub(r\"Q\\('([^']*)'\\)|C\\(([^)]*)\\)\", r\"\\1\\2\", term).strip() for term in terms\n",
    "    ]\n",
    "\n",
    "    # Remove duplicates and sort the column names\n",
    "    return sorted({name for name in column_names if name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_STUDY_MODELS = [\n",
    "    \"Q('10y_Maturity_Bond_Yield') ~ Q('Public_Debt_as_%_of_GDP')+ GDP_in_Current_Prices_Growth + Moody_Rating_PD + \"\n",
    "    \"VIX_Daily_Close_Quarterly_Mean + Q('10y_Maturity_Bond_Yield_US') + C(Country) + C(Date) +\",\n",
    "    \"Q('10y_Maturity_Bond_Yield') ~ Q('Public_Debt_as_%_of_GDP')+ GDP_in_Current_Prices_Growth + Moody_Rating_PD + \"\n",
    "    \"VIX_Daily_Close_Quarterly_Mean + Q('10y_Maturity_Bond_Yield_US') + C(Country) +\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_event_study_for_given_configuration(\n",
    "    event_study_data,\n",
    "    configuraton,\n",
    "    event_study_countries,\n",
    "    event_study_time_period,\n",
    "    standard_errors=\"hac-panel\",\n",
    "):\n",
    "    \"\"\"This function runs a regression with the dataset as an input and the given configuration. THe function returns the statsmodel.model object.\"\"\"\n",
    "    # Drop all rows where a variable in the formula is NA and the US\n",
    "    columns_for_dropping = extract_column_names_from_regression_formula(configuraton)\n",
    "    data = event_study_data.dropna(subset=columns_for_dropping)\n",
    "    data = data.loc[data[\"Country\"] != \"usa\", :]\n",
    "\n",
    "    # Make the event study configuration:\n",
    "\n",
    "    formula = configuraton + \" + \".join(\n",
    "        f\"Dummy_{country}_{quarter}\"\n",
    "        for country in event_study_countries\n",
    "        for quarter in pd.period_range(\n",
    "            start=event_study_time_period[0],\n",
    "            end=event_study_time_period[1],\n",
    "            freq=\"Q\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Sort the data\n",
    "    # (This is required for the HAC standard errors to work correctly)\n",
    "\n",
    "    data = data.sort_values(by=[\"Country\", \"Date\"])\n",
    "\n",
    "    # Run the regression\n",
    "    return smf.ols(formula=formula, data=data).fit(\n",
    "        cov_type=standard_errors,\n",
    "        cov_kwds={\"groups\": data[\"Country\"], \"maxlags\": 2},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = run_event_study_for_given_configuration(\n",
    "    event_study_data,\n",
    "    EVENT_STUDY_MODELS[0],\n",
    "    EVENT_STUDY_COUNTRIES,\n",
    "    EVENT_STUDY_TIME_PERIOD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trained_model.params.keys().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parameters_for_regression_table_from_model(model, configuration):\n",
    "    # Define the significance levels\n",
    "    significance_levels = [0.01, 0.05, 0.1]\n",
    "\n",
    "    # Define the stars for each significance level\n",
    "    stars = [\"***\", \"**\", \"*\"]\n",
    "\n",
    "    # Define the parameters to extract\n",
    "    parameters = [\n",
    "        \"Q('Public_Debt_as_%_of_GDP')\",\n",
    "        \"GDP_in_Current_Prices_Growth\",\n",
    "        \"Moody_Rating_PD\",\n",
    "        \"VIX_Daily_Close_Quarterly_Mean\",\n",
    "        \"Q('10y_Maturity_Bond_Yield_US')\",\n",
    "        \"Q('3_Month_US_Treasury_Yield_Quarterly_Mean')\",\n",
    "        \"Q('NASDAQ_Value_Quarterly_Mean')\",\n",
    "        \"Q('Current_Account_in_USD')\",\n",
    "        \"'Eurostat_CPI_Annualised Growth_Rate\",\n",
    "    ]\n",
    "\n",
    "    # Initialize an empty dictionary to store the coefficients with stars\n",
    "    coefficients_with_stars = {}\n",
    "\n",
    "    # Loop over each parameter\n",
    "    for param in parameters:\n",
    "        # Get the coefficient value\n",
    "        coefficient = model.params.get(param, \"\")\n",
    "\n",
    "        # Get the p-value of the coefficient\n",
    "        p_value = model.pvalues.get(param, 1)\n",
    "\n",
    "        # Add stars to the coefficient based on its p-value\n",
    "        for level, star in zip(significance_levels, stars):\n",
    "            if p_value < level:\n",
    "                coefficient = f\"{coefficient:.2f}{star}\"\n",
    "                break\n",
    "\n",
    "        # Add the coefficient with stars to the dictionary\n",
    "        coefficients_with_stars[param] = coefficient\n",
    "\n",
    "    # Check for fixed effects\n",
    "    country_fe = \"Yes\" if \"C('Country')\" in configuration else \"No\"\n",
    "    time_fe = \"Yes\" if \"C('Date')\" in configuration else \"No\"\n",
    "\n",
    "    # Add other model statistics to the dictionary\n",
    "    coefficients_with_stars.update(\n",
    "        {\n",
    "            \"Country Fixed Effects\": country_fe,\n",
    "            \"Time Fixed Effects\": time_fe,\n",
    "            \"Number of Observations\": round(model.nobs, 0),\n",
    "            \"R-Squared\": round(model.rsquared, 2),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Convert the dictionary to a pandas Series and return it\n",
    "    return pd.Series(coefficients_with_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters_for_regression_table_for_configuration(\n",
    "    event_study_data,\n",
    "    configuraton,\n",
    "    event_study_countries,\n",
    "    event_study_time_period,\n",
    "    standard_errors=\"hac-panel\",\n",
    "):\n",
    "    model = run_event_study_for_given_configuration(\n",
    "        event_study_data,\n",
    "        configuraton,\n",
    "        event_study_countries,\n",
    "        event_study_time_period,\n",
    "        standard_errors,\n",
    "    )\n",
    "\n",
    "    return extract_parameters_for_regression_table_from_model(model, configuraton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_parameters_for_regression_table_for_configuration(\n",
    "    event_study_data,\n",
    "    EVENT_STUDY_MODELS[0],\n",
    "    EVENT_STUDY_COUNTRIES,\n",
    "    EVENT_STUDY_TIME_PERIOD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regresssion_table_for_list_of_configurations(\n",
    "    event_study_data,\n",
    "    EVENT_STUDY_MODELS,\n",
    "    EVENT_STUDY_COUNTRIES,\n",
    "    EVENT_STUDY_TIME_PERIOD,\n",
    "):\n",
    "    # Initialize empty dataframe to store results\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    # Loop over each configuration\n",
    "    for index, configuration in enumerate(EVENT_STUDY_MODELS):\n",
    "        parameters = get_parameters_for_regression_table_for_configuration(\n",
    "            event_study_data,\n",
    "            configuration,\n",
    "            EVENT_STUDY_COUNTRIES,\n",
    "            EVENT_STUDY_TIME_PERIOD,\n",
    "        )\n",
    "        results[str(index)] = parameters\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_regresssion_table_for_list_of_configurations(\n",
    "    event_study_data,\n",
    "    EVENT_STUDY_MODELS,\n",
    "    EVENT_STUDY_COUNTRIES,\n",
    "    EVENT_STUDY_TIME_PERIOD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_debt = trained_model.params.get(\"Q('Public_Debt_as_%_of_GDP')\", \"\")\n",
    "real_gdp_growth = trained_model.params.get(\"GDP_in_Current_Prices_Growth\", \"\")\n",
    "moody_rating = trained_model.params.get(\"Moody_Rating_PD\", \"\")\n",
    "vix = trained_model.params.get(\"VIX_Daily_Close_Quarterly_Mean\", \"\")\n",
    "us_bond_yield = trained_model.params.get(\"Q('10y_Maturity_Bond_Yield_US')\", \"\")\n",
    "three_month_us_trasury = trained_model.params.get(\n",
    "    \"Q('3_Month_US_Treasury_Yield_Quarterly_Mean')\",\n",
    "    \"\",\n",
    ")\n",
    "nasdaq_value = trained_model.params.get(\"Q('NASDAQ_Value_Quarterly_Mean')\", \"\")\n",
    "current_account = trained_model.params.get(\"Q('Current_Account_in_USD')\", \"\")\n",
    "consumer_price_index = trained_model.params.get(\n",
    "    \"'Eurostat_CPI_Annualised Growth_Rate\",\n",
    "    \"\",\n",
    ")\n",
    "number_obserations = trained_model.nobs\n",
    "r_squared = trained_model.rsquared\n",
    "country_fe = \"Yes\" if \"C('Country')\" in configuration else \"No\"\n",
    "\n",
    "time_fe = \"Yes\" if \"C('Date')\" in configuration else \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/event_study_approach/event_study_regression_table_data.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Plot with Daily Sentiment and event study coefficient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_coefficients = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/event_study_approach/event_study_coefficients_data_negative_and_positive_20_.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_coefficients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdonald_sentiment_daily = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/mcdonald_sentiment_index_cleaned_negative_and_positive_20_.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdonald_sentiment_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make correlation table bond spread, sentiment index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_data = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/event_study_approach/event_study_full_model_data_negative_and_positive_20_.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event_study_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'Country' and calculate the correlation of 'Bond_Yield_Spread' and 'McDonald_Sentiment_Index'\n",
    "correlations = event_study_data.groupby(\"Country\").apply(\n",
    "    lambda x: x[[\"Bond_Yield_Spread\", \"McDonald_Sentiment_Index\"]].corr().iloc[0, 1],\n",
    ")\n",
    "\n",
    "# Convert the Series to a DataFrame\n",
    "correlations = correlations.to_frame().reset_index()\n",
    "# Rename the columns\n",
    "correlations.columns = [\"Country\", \"Correlation\"]\n",
    "\n",
    "# Drop NA's and round\n",
    "correlations = correlations.dropna().round(2)\n",
    "\n",
    "# Capitalise the country names\n",
    "correlations[\"Country\"] = correlations[\"Country\"].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/df_transcripts_clean_step_2_negative_and_positive_20_.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_greece = sentiments[\n",
    "    sentiments[\"Sentiment_Index_McDonald_greece\"] <= -0.2\n",
    "].sort_values(\"Sentiment_Index_McDonald_greece\")[\n",
    "    [\n",
    "        \"Date\",\n",
    "        \"Sentiment_Index_McDonald_greece\",\n",
    "        \"Preprocessed_Transcript_Step_1\",\n",
    "        \"Company\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_greece.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_word_count = pd.read_csv(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/sentiment_data/sentiment_word_count_clean.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_data = (\n",
    "    sentiment_word_count[(sentiment_word_count[\"Positive_Indicator\"] == 1)]\n",
    "    .sort_values(by=\"Count\", ascending=False)\n",
    "    .head(20)\n",
    ")\n",
    "\n",
    "# Sort the DataFrame\n",
    "sorted_data = filtered_data.sort_values(by=\"Count\", ascending=False)\n",
    "\n",
    "# Create the plot\n",
    "fig = plt.figure(figsize=(8, 7))\n",
    "\n",
    "plt.barh(sorted_data[\"Word\"], sorted_data[\"Count\"], color=\"#3c5488\")\n",
    "plt.xlabel(\"Total Number of Occurences\")\n",
    "plt.yticks(fontsize=8)  # Adjust font size here\n",
    "\n",
    "# Remove the top and right spines from plot\n",
    "sns.despine()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_data = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/sentiment_dictionary_clean.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_data[\"Negative_Indicator\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary_data.loc[dictionary_data[\"Negative_Indicator\"] == 1, \"Word\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_data[\"Positive_Indicator\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary_data.loc[dictionary_data[\"Positive_Indicator\"] == 1, \"Word\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_data = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/event_study_approach/event_study_full_model_data_negative_and_positive_20_.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_data.columns[1:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dexcriptive Statistics\n",
    "\n",
    "# Group the data by 'Country' and calculate the mean of the specified columns\n",
    "average_data = event_study_data.groupby(\"Country\")[\n",
    "    [\n",
    "        \"Public_Debt_as_%_of_GDP\",\n",
    "        \"10y_Maturity_Bond_Yield\",\n",
    "        \"GDP_in_Current_Prices_Growth\",\n",
    "    ]\n",
    "].mean()\n",
    "\n",
    "# Calculate the most frequent 'Rating_Moody_Last_Quarter_Day' for each country\n",
    "average_data[\"Most Frequent Rating_Moody_Last_Quarter_Day\"] = event_study_data.groupby(\n",
    "    \"Country\",\n",
    ")[\"Rating_Moody_Last_Quarter_Day\"].agg(pd.Series.mode)\n",
    "\n",
    "# Calculate the number of observations for each country\n",
    "average_data[\"Number of Observations\"] = event_study_data.groupby(\"Country\").size()\n",
    "\n",
    "average_data = average_data.round(2)\n",
    "\n",
    "# Reset the index\n",
    "average_data = average_data.reset_index()\n",
    "\n",
    "average_data[\"Country\"] = average_data[\"Country\"].str.title()\n",
    "\n",
    "# Insert empty columns for breaks\n",
    "average_data.insert(2, \"Break1\", \"\")\n",
    "average_data.insert(5, \"Break2\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataframe_content_to_latex_table_body(data):\n",
    "    # Convert each row to a string with ' & ' as the separator\n",
    "    data_string = data.apply(lambda row: \" & \".join(row.astype(str)), axis=1)\n",
    "\n",
    "    # Join all rows into a single string with ' \\\\\\\\\\n' as the separator\n",
    "    data_string = \" \\\\\\\\\".join(data_string)\n",
    "\n",
    "    # Add ' \\\\\\\\' at the end of the string\n",
    "    data_string += \" \\\\\\\\\"\n",
    "\n",
    "    return data_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_missing_values_heatmap(data, data_name, index=None):\n",
    "    \"\"\"Create a heatmap to visualize missing values in a DataFrame.\"\"\"\n",
    "    if index is not None:\n",
    "        data = data.set_index(index)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(data.isnull(), cbar=False, cmap=\"viridis\")\n",
    "    plt.title(\"Missing Values in Dataset \" + data_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_coefficients = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/event_study_approach/event_study_coefficients_data.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_coefficients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_data = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/event_study_approach/event_study_dataset_negative_and_positive_20_.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chile_data = event_study_data.loc[event_study_data[\"Country\"] == \"chile\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_make_missing_values_heatmap(\n",
    "    chile_data[\n",
    "        [\n",
    "            \"date\",\n",
    "            \"Country\",\n",
    "            \"Date\",\n",
    "            \"GDP_in_USD_Current_Prices\",\n",
    "            \"REF_AREA\",\n",
    "            \"Eurostat_CPI_Annualised Growth_Rate\",\n",
    "            \"Public_Debt_as_%_of_GDP\",\n",
    "            \"Real_Quarterly_GVA_in_Domestic_Currency\",\n",
    "            \"Current_Account_in_USD\",\n",
    "            \"Rating_Moody_Last_Quarter_Day\",\n",
    "        ]\n",
    "    ],\n",
    "    \"Germany Data\",\n",
    "    index=\"Date\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_data[\"10y_Maturity_Bond_Yield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_data.Country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_index_and_bond_yield_spread_for_country(\n",
    "    first_step_regression_data,\n",
    "    country,\n",
    "    color_scheme=None,\n",
    "):\n",
    "    # Filter the data for the given country\n",
    "    if color_scheme is None:\n",
    "        color_scheme = [\"#3c5488\", \"#e64b35\", \"#4dbbd5\", \"#00a087\", \"#f39b7f\"]\n",
    "    country_data = first_step_regression_data[\n",
    "        first_step_regression_data[\"Country\"] == country\n",
    "    ]\n",
    "    country_data = country_data.sort_values(\"Date\")\n",
    "\n",
    "    # Set the style of the plot\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    ax1.plot(\n",
    "        country_data[\"Date\"],\n",
    "        country_data[\"Bond_Yield_Spread\"],\n",
    "        marker=\"o\",\n",
    "        color=color_scheme[0],\n",
    "        label=f\"Bond Yield Spread {country.capitalize()} \",\n",
    "    )\n",
    "    ax1.set_ylabel(\"Bond Yield Spread in Basis Points\", fontsize=14)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(\n",
    "        country_data[\"Date\"],\n",
    "        country_data[\"McDonald_Sentiment_Index\"],\n",
    "        marker=\"o\",\n",
    "        color=color_scheme[1],\n",
    "        label=f\"Sentiment Index {country.capitalize()} \",\n",
    "    )\n",
    "    ax2.set_ylabel(\"Sentiment Index\", fontsize=14)\n",
    "    ax2.invert_yaxis()  # Invert the right y-axis\n",
    "\n",
    "    # Add a horizontal line at y=0\n",
    "\n",
    "    # Set the title and labels\n",
    "    plt.title(\n",
    "        f\"Raw Sentiment Data {country.capitalize()} with Bond Yield Spread for {country.capitalize()} \",\n",
    "        fontsize=16,\n",
    "    )\n",
    "    plt.xlabel(\"Date\", fontsize=14)\n",
    "\n",
    "    # Keep only the y-axis and x-axis\n",
    "    sns.despine(left=False, bottom=False, right=False, top=True)\n",
    "\n",
    "    # Create a legend for both lines\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
    "\n",
    "    # Use LaTeX style for the font\n",
    "    plt.rc(\"text\", usetex=True)\n",
    "\n",
    "    # Align the zero of both y-axes\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_sentiment_index_and_bond_yield_spread_for_country(\n",
    "    event_study_data,\n",
    "    \"portugal\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal_filter = event_study_data[event_study_data[\"Country\"] == \"portugal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal_filter[\"McDonald_Sentiment_Index\"].corr(portugal_filter[\"Bond_Yield_Spread\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"^Dummy_\\w+_\\w+$\"\n",
    "coefficient_data = event_study_data.loc[\n",
    "    event_study_data[\"Variable\"].str.contains(pattern, regex=True),\n",
    "    :,\n",
    "]\n",
    "\n",
    "coefficient_data[\"Date\"] = pd.to_datetime(\n",
    "    coefficient_data[\"Variable\"].str.split(\"_\").str[-1],\n",
    ")\n",
    "coefficient_data[\"Country\"] = coefficient_data[\"Variable\"].str.split(\"_\").str[-2]\n",
    "coefficient_data[\"CI_95_lower\"] = (\n",
    "    coefficient_data[\"Coefficient\"] - coefficient_data[\"Standard Errors\"] * 1.96\n",
    ")\n",
    "coefficient_data[\"CI_95_upper\"] = (\n",
    "    coefficient_data[\"Coefficient\"] + coefficient_data[\"Standard Errors\"] * 1.96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficient_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nature_color_scheme = [\"#3c5488\", \"#e64b35\", \"#4dbbd5\", \"#00a087\", \"#f39b7f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style of the plot\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Filter the data for the given country\n",
    "greece_data = coefficient_data[coefficient_data[\"Country\"] == \"greece\"]\n",
    "greece_data = greece_data.sort_values(\"Date\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    greece_data[\"Date\"],\n",
    "    greece_data[\"Coefficient\"],\n",
    "    marker=\"o\",\n",
    "    color=nature_color_scheme[0],\n",
    ")\n",
    "\n",
    "# Add a horizontal line at y=0\n",
    "plt.axhline(0, color=\"grey\", linestyle=\":\")\n",
    "\n",
    "# Plot the confidence interval\n",
    "plt.fill_between(\n",
    "    greece_data[\"Date\"],\n",
    "    greece_data[\"CI_95_lower\"],\n",
    "    greece_data[\"CI_95_upper\"],\n",
    "    color=\"b\",\n",
    "    alpha=0.1,\n",
    ")\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title(\"Coefficients for Greece Over Time with Confidence Interval\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=14)\n",
    "plt.ylabel(\"Coefficient\", fontsize=14)\n",
    "\n",
    "# Remove the legend\n",
    "\n",
    "# Keep only the y-axis and x-axis\n",
    "sns.despine(left=False, bottom=False, right=True, top=True)\n",
    "\n",
    "# Use LaTeX style for the font\n",
    "plt.rc(\"text\", usetex=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_STUDY_COUNTRIES = [\n",
    "    \"netherlands\",\n",
    "    \"latvia\",\n",
    "    \"austria\",\n",
    "    \"italy\",\n",
    "    \"finland\",\n",
    "    \"slovenia\",\n",
    "    \"lithuania\",\n",
    "    \"greece\",\n",
    "    \"portugal\",\n",
    "    \"spain\",\n",
    "    \"germany\",\n",
    "    \"belgium\",\n",
    "    \"ireland\",\n",
    "    \"france\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" + \".join(\n",
    "    [\n",
    "        f\"Dummy_{country}_{quarter}\"\n",
    "        for country in EVENT_STUDY_COUNTRIES\n",
    "        for quarter in pd.period_range(start=\"2009Q1\", end=\"2011Q4\", freq=\"Q\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = (\n",
    "    \"Bond_Yield_Spread ~ Q('Public_Debt_as_%_of_GDP')+ GDP_in_Current_Prices_Growth + \"\n",
    "    \"GDP_in_Current_Prices_Growth_Lead + Current_Account_in_USD + \"\n",
    "    \"VIX_Daily_Close_Quarterly_Mean + Q('Eurostat_CPI_Annualised Growth_Rate') + \"\n",
    "    \"NASDAQ_Daily_Close_Quarterly_Mean + Q('3_Month_US_Treasury_Yield_Quarterly_Mean')\"\n",
    "    + \" + \".join(\n",
    "        [\n",
    "            f\"Dummy_{country}_{quarter}\"\n",
    "            for country in EVENT_STUDY_COUNTRIES\n",
    "            for quarter in pd.period_range(start=\"2009Q1\", end=\"2009Q4\", freq=\"Q\")\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/event_study_approach/event_study_coefficients_data.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quarter_columns(df):\n",
    "    quarters = pd.period_range(start=\"2009Q1\", end=\"2011Q4\", freq=\"Q\")\n",
    "    for quarter in quarters:\n",
    "        start_date = quarter.start_time\n",
    "        end_date = quarter.end_time\n",
    "        df[str(quarter)] = (\n",
    "            (df[\"Date\"] >= start_date)\n",
    "            & (df[\"Date\"] <= end_date)\n",
    "            & (df[\"Country\"] == \"Greece\")\n",
    "        ).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_data = pd.read_pickle(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/step_one_regression_dataset_output_quarterly.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = pd.read_csv(\n",
    "    \"/Users/nicolasroever/Documents/Promotion/Debt Crisis/debt_crisis/bld/data/sentiment_data/sentiment_word_count_clean.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot positives\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_data = dictionary[\n",
    "    (dictionary[\"Positive_Indicator\"] == 1) & (dictionary[\"Count\"] > 600)\n",
    "]\n",
    "\n",
    "# Sort the DataFrame\n",
    "sorted_data = filtered_data.sort_values(by=\"Count\", ascending=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_data[\"Word\"], sorted_data[\"Count\"])\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Word Counts for Positive Words\")\n",
    "plt.yticks(fontsize=8)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot positives\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_data_2 = dictionary[\n",
    "    (dictionary[\"Negative_Indicator\"] == 1) & (dictionary[\"Count\"] > 600)\n",
    "]\n",
    "\n",
    "# Sort the DataFrame\n",
    "sorted_data_2 = filtered_data_2.sort_values(by=\"Count\", ascending=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_data_2[\"Word\"], sorted_data_2[\"Count\"])\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Word Counts for Negativev Words\")\n",
    "plt.yticks(fontsize=8)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.sort_values(by=\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.columns = [\"Word\", \"Count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRIES_UNDER_STUDY = {\n",
    "    \"austria\",\n",
    "    \"belgium\",\n",
    "    \"bulgaria\",\n",
    "    \"croatia\",\n",
    "    \"cyprus\",\n",
    "    \"czechia\",\n",
    "    \"denmark\",\n",
    "    \"estonia\",\n",
    "    \"finland\",\n",
    "    \"france\",\n",
    "    \"germany\",\n",
    "    \"greece\",\n",
    "    \"hungary\",\n",
    "    \"ireland\",\n",
    "    \"italy\",\n",
    "    \"latvia\",\n",
    "    \"lithuania\",\n",
    "    \"luxembourg\",\n",
    "    \"malta\",\n",
    "    \"netherlands\",\n",
    "    \"poland\",\n",
    "    \"portugal\",\n",
    "    \"romania\",\n",
    "    \"slovakia\",\n",
    "    \"slovenia\",\n",
    "    \"spain\",\n",
    "    \"sweden\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartertly_countries = set(quarterly_data[\"Country\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_countries = COUNTRIES_UNDER_STUDY.intersection(quartertly_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "Find the parameters at https://data-explorer.oecd.org/vis?df[ds]=dsDisseminateFinalDMZ&df[id]=DSD_NAMAIN1%40DF_QNA_EXPENDITURE_USD&df[ag]=OECD.SDD.NAD&df[vs]=1.0&pd=%2C&dq=Q..AUS.S1..B1GQ.....V..&ly[cl]=TIME_PERIOD&to[TIME_PERIOD]=false&lo=5&lom=LASTNPERIODS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://sdmx.oecd.org/public/rest/data/OECD.SDD.TPS,DSD_BOP@DF_BOP,1.0/USA..CA.B..Q.USD_EXC+XDC.N?dimensionAtObservation=AllDimensions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_data = xmltodict.parse(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_data[\"message:GenericData\"][\"message:DataSet\"][\"generic:Obs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_dictionary = dictionary_data[\"message:GenericData\"][\"message:DataSet\"][\n",
    "    \"generic:Obs\"\n",
    "][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_data[\"message:GenericData\"][\"message:DataSet\"][\"generic:Obs\"][0][\n",
    "    \"generic:ObsValue\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. obskey\n",
    "obs_key_data = observation_dictionary[\"generic:ObsKey\"][\"generic:Value\"]\n",
    "obs_key_dict = {d[\"@id\"]: d[\"@value\"] for d in obs_key_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obs value\n",
    "obs_value_dict = observation_dictionary[\"generic:ObsValue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obs value\n",
    "obs_attributes_data = observation_dictionary[\"generic:Attributes\"][\"generic:Value\"]\n",
    "obs_attributes_dict = {d[\"@id\"]: d[\"@value\"] for d in obs_attributes_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_observation = {**obs_key_dict, **obs_value_dict, **obs_attributes_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(full_observation, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(\n",
    "    len(dictionary_data[\"message:GenericData\"][\"message:DataSet\"][\"generic:Obs\"]),\n",
    "):\n",
    "    observation_dictionary = dictionary_data[\"message:GenericData\"][\"message:DataSet\"][\n",
    "        \"generic:Obs\"\n",
    "    ][i]\n",
    "    # 1. obskey\n",
    "    obs_key_data = observation_dictionary[\"generic:ObsKey\"][\"generic:Value\"]\n",
    "    obs_key_dict = {d[\"@id\"]: d[\"@value\"] for d in obs_key_data}\n",
    "    # Obs value\n",
    "    obs_value_dict = observation_dictionary[\"generic:ObsValue\"]\n",
    "    # ObsAttributes\n",
    "    obs_attributes_data = observation_dictionary[\"generic:Attributes\"][\"generic:Value\"]\n",
    "    obs_attributes_dict = {d[\"@id\"]: d[\"@value\"] for d in obs_attributes_data}\n",
    "\n",
    "    full_observation = {**obs_key_dict, **obs_value_dict, **obs_attributes_dict}\n",
    "    full_data = pd.concat([full_data, pd.DataFrame(full_observation, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"COUNTERPART_AREA\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set out everything about the request in the format specified by the OECD API\n",
    "data = oecd.data(resource_id=\"DSD_NAMAIN1\").to_pandas()\n",
    "\n",
    "df = pd.DataFrame(data).reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MEASURE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell pdmx we want OECD data\n",
    "oecd = pdmx.Request(\"OECD\")\n",
    "# Set out everything about the request in the format specified by the OECD API\n",
    "data = oecd.data(\n",
    "    resource_id=\"PDB_LV\",\n",
    "    key=\"GBR+FRA+CAN+ITA+DEU+JPN+USA.T_GDPEMP.CPC/all?startTime=2010\",\n",
    ").to_pandas()\n",
    "\n",
    "df = pd.DataFrame(data).reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.content[\"OECD.SDD.NAD:DSD_NAMAIN1@DF_QNA_EXPENDITURE_CAPITA(1.0)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_xml(\n",
    "    \"https://sdmx.oecd.org/public/rest/data/OECD.SDD.NAD,DSD_NAMAIN1@DF_QNA_EXPENDITURE_CAPITA,1.0/Q............?startPeriod=2022-Q4&dimensionAtObservation=AllDimensions\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
